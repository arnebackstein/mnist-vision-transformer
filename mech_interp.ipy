# %%
import torch
from model import VisionTransformer
from data import get_device, get_mnist_data
import matplotlib.pyplot as plt
import numpy as np

device = get_device()
data = get_mnist_data()
train_loader, _ = data
sample_input, _ = next(iter(train_loader))
sample_input = sample_input[0:1]
sample_input = sample_input.to(device)

patch_size=4
num_patches = 28 // patch_size
model = VisionTransformer(
    image_size=28,
    patch_size=patch_size, 
    num_classes=10,
    dim=32,
    depth=4,
    heads=4,
    mlp_dim=64,
    channels=1
).to(device)

checkpoint = torch.load('models/final_model.pt')
model.load_state_dict(checkpoint['model_state_dict'])
model.eval() 

attention_patterns = []

def hook_fn(module, input, output):
    patterns = module.get_attention_patterns()
    attention_patterns.append(patterns.detach())

for layer in model.transformer.layers:
    layer.register_forward_hook(hook_fn)

with torch.no_grad():
    output = model(sample_input)

attention_patterns = torch.stack(attention_patterns)

print("Attention patterns shape:", attention_patterns.shape)

original_image = sample_input.squeeze().cpu().numpy()

fig, axs = plt.subplots(4, 4, figsize=(15, 15))

for layer_idx in range(4):
    for head_idx in range(4):
        patterns = attention_patterns[layer_idx, 0, head_idx]
        cls_attention = patterns[0, 1:].cpu().numpy()
        cls_attention_grid = cls_attention.reshape(num_patches, num_patches)
        
        attention_overlay = np.zeros((28, 28))
        for i in range(num_patches):
            for j in range(num_patches):
                attention_overlay[i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size] = cls_attention_grid[i, j]
        
        attention_overlay = (attention_overlay - attention_overlay.min()) / (attention_overlay.max() - attention_overlay.min())
        
        ax = axs[layer_idx, head_idx]
        
        colored_attention = plt.cm.YlOrBr(attention_overlay)
        image_colored = plt.cm.gray(original_image)
        
        blended = 0.6 * image_colored + 0.4 * colored_attention
        
        blended[..., 3] = 1
        
        ax.imshow(blended)
        ax.set_title(f'Layer {layer_idx+1}, Head {head_idx+1}')
        ax.axis('off')

plt.tight_layout()
plt.show()

print("Prediction:", output.argmax(dim=1).item())

# %%
